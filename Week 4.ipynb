{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this week's work, I'm going to apply the pre-trained model described in the [Lample et al](https://arxiv.org/abs/1603.01360) paper. We've been referring to this as a \"Glample\" model, so I'll stick with that. In this work, they use a bi-directional LSTM with a conditional random field on top to output the classes. Performance is roughly on par with other systems, but provides the advantage of being language agnostic and does not rely on any external labeled data (e.g. gazetteer). Performance on Spanish and German surpasses previous state-of-the-art.\n",
    "\n",
    "To evaluate the glample model, I need to write an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "files = glob.glob('data/audible/processedText/*.xml')\n",
    "outdat = open('audible_files.txt', 'w')\n",
    "for f in files:\n",
    "    xml_data = open(f).read()\n",
    "    soup = BeautifulSoup(xml_data, 'lxml')\n",
    "    sentences = soup.find_all('s')\n",
    "    for s in sentences:\n",
    "        tokens = s.find_all(['w', 'c'])\n",
    "        for i in tokens:\n",
    "            outdat.write(i.text.encode('utf8'))\n",
    "            outdat.write(' ')\n",
    "        outdat.write('\\n')\n",
    "\n",
    "outdat.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having written this file, I ran it through glample via the command-line utility function. It returned an output file in which the words were tagged as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"__O There__O was__O no__O water__O in__O the__O cat__O \\'s__O bowl__O ,__O \"__O she__O said__O .__O\\n',\n",
       " '\"__O He__O drinks__O out__O of__O the__O toilet__O ,__O \"__O I__O said__O .__O\\n',\n",
       " '\"__O That__O \\'s__O disgusting__O .__O \"__O\\n',\n",
       " '\"__O That__O \\'s__O what__O I__O \\'ve__O been__O telling__O him__O ,__O \"__O I__O said__O .__O\\n',\n",
       " 'But__O she__O saw__O no__O humor__O in__O my__O remark__O .__O\\n',\n",
       " 'She__O served__O oatmeal__O in__O two__O bowls__O and__O placed__O them__O on__O the__O breakfast__O table__O ,__O then__O began__O hunting__O for__O spoons__O and__O coffee__O cups__O .__O\\n',\n",
       " 'I__O looked__O at__O my__O watch__O .__O\\n',\n",
       " '\"__O I__O \\'m__O running__O a__O little__O bit__O late__O for__O Mass__B-ORG ,__O \"__O I__O lied__O .__O\\n',\n",
       " '\"__O Where__O \\'s__O your__O butter__O dish__O ?__O \"__O\\n',\n",
       " '\"__O I__O do__O n\\'t__O have__O one__O .__O\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('tagger-master/output.txt')\n",
    "glampledat = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glampletags = []\n",
    "for i, sentence in enumerate(glampledat):\n",
    "    glampletags.append(enumerate(sentence.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audible_text = []\n",
    "audible_tag = []\n",
    "for f in files:\n",
    "    xml_data = open(f).read()\n",
    "    soup = BeautifulSoup(xml_data, 'lxml')\n",
    "    sentences = soup.find_all('s')\n",
    "    for j, s in enumerate(sentences):\n",
    "        words = s.find_all(['w', 'c'])\n",
    "        doc = ' '.join(w.text.encode('utf8') for w in words)\n",
    "        for i, w in enumerate(words):\n",
    "            if 'ner' in w.attrs:\n",
    "                audible_text.append(w.text)\n",
    "                audible_tag.append(w.attrs['ner'])\n",
    "            else:\n",
    "                audible_text.append(w.text)\n",
    "                audible_tag.append('O-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glample_text = []\n",
    "glample_tag = []\n",
    "audible_text = []\n",
    "audible_tag = []\n",
    "for f in files:\n",
    "    xml_data = open(f).read()\n",
    "    soup = BeautifulSoup(xml_data, 'lxml')\n",
    "    sentences = soup.find_all('s')\n",
    "    for j, s in enumerate(sentences):\n",
    "        glample_sent = glampletags[j]\n",
    "        glample_words = glample_sent.split('__')\n",
    "        words = s.find_all(['w', 'c'])\n",
    "        doc = ' '.join(w.text.encode('utf8') for w in words)\n",
    "        if len(glample_words) == len(words):\n",
    "            for i, w in enumerate(words):\n",
    "                if 'ner' in w.attrs:\n",
    "                    glample_text.append(stanford_words[i][0])\n",
    "                    glample_tag.append(stanford_words[i][1])\n",
    "                    audible_text.append(w.text)\n",
    "                    audible_tag.append(w.attrs['ner'])\n",
    "                else:\n",
    "                    stanford_text.append(stanford_words[i][0])\n",
    "                    stanford_tag.append(stanford_words[i][1])\n",
    "                    audible_text.append(w.text)\n",
    "                    audible_tag.append('O-')\n",
    "        else:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'yourself', u'. . . .', u'Take', u'care', u'of', u'your', u'tools', u'and', u'they', u\"'ll\", u'take', u'care', u'of', u'you', u'. . . .', u'Put', u'your', u'shotgun', u'through', u'the', u'fence', u',', u'then', u'crawl', u'after']\n",
      "[['yourself', 'O'], ['.', 'O'], ['.', 'O'], ['.', 'O'], ['.', 'O'], ['Take', 'O'], ['care', 'O'], ['of', 'O'], ['your', 'O'], ['tools', 'O'], ['and', 'O'], ['they', 'O'], [\"'ll\", 'O'], ['take', 'O'], ['care', 'O'], ['of', 'O'], ['you', 'O'], ['.', 'O'], ['.', 'O'], ['.', 'O'], ['.', 'O'], ['Put', 'O'], ['your', 'O'], ['shotgun', 'O'], ['through', 'O']]\n"
     ]
    }
   ],
   "source": [
    "#print len(audible_text)\n",
    "#print len(glampletags)\n",
    "\n",
    "print audible_text[14850:14875]\n",
    "print glampletags[14850:14875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from loader import prepare_sentence\n",
    "model = Model(model_path='models/english/')\n",
    "parameters = model.parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def condense_glample_tokens(audible_sentence, glample_words, glample_tag, audible_text, audible_tag):\n",
    "    offset = [0,0] #stanford, audible\n",
    "    words = audible_sentence.find_all(['w', 'c'])\n",
    "    doc = ' '.join(w.text.encode('utf8') for w in words)\n",
    "    if len(glample_words) > len(words):\n",
    "        for i, w in enumerate(words):\n",
    "            stanford_words = word_tokenize(w.text)\n",
    "            if len(stanford_words) == 1:\n",
    "                if 'ner' in w.attrs:\n",
    "                    stanford_text.append(stanford_tags[i+offset[0]][0]) \n",
    "                    stanford_tag.append(stanford_tags[i+offset[0]][1])\n",
    "                    audible_text.append(w.text)\n",
    "                    audible_tag.append(w.attrs['ner'])\n",
    "                else:\n",
    "                    stanford_text.append(stanford_tags[i+offset[0]][0]) \n",
    "                    stanford_tag.append(stanford_tags[i+offset[0]][1])\n",
    "                    audible_text.append(w.text)\n",
    "                    audible_tag.append('O-')\n",
    "            else:\n",
    "                if 'ner' in w.attrs:\n",
    "                    stanford_text.append(''.join(j[0] for j in stanford_tags[i+offset[0]:i+offset[0]+len(stanford_words)])) \n",
    "                    stanford_tag.append(''.join(j[1] for j in stanford_tags[i+offset[0]:i+offset[0]+len(stanford_words)]))\n",
    "                    audible_text.append(w.text)\n",
    "                    audible_tag.append(w.attrs['ner'])\n",
    "                else:\n",
    "                    stanford_text.append(''.join(j[0] for j in stanford_tags[i+offset[0]:i+offset[0]+len(stanford_words)])) \n",
    "                    stanford_tag.append(''.join(j[1] for j in stanford_tags[i+offset[0]:i+offset[0]+len(stanford_words)]))\n",
    "                    audible_text.append(w.text)\n",
    "                    audible_tag.append('O-')\n",
    "\n",
    "                offset[0] += len(stanford_words)-1\n",
    "    else:\n",
    "        offset[1] = len(stanford_tags)\n",
    "        while len(words)>len(stanford_tags):\n",
    "            try:\n",
    "                doc = ' '.join(w.text.encode('utf8') for w in words[offset[1]:])\n",
    "                stanford_tags.extend(stanford_mod.tag([doc]))\n",
    "            except:\n",
    "                doc = ' '.join(w.text.encode('utf8') for w in words[offset[1]:])\n",
    "                stanford_tags.extend(stanford_mod.tag([doc.decode('ascii', 'ignore')]))\n",
    "            offset[1] = len(stanford_tags)\n",
    "        for i, w in enumerate(stanford_tags):   \n",
    "            if 'ner' in words[i].attrs:\n",
    "                stanford_text.append(w[0])\n",
    "                stanford_tag.append(w[1])\n",
    "                audible_text.append(words[i].text)\n",
    "                audible_tag.append(words[i].attrs['ner'])\n",
    "            else:\n",
    "                stanford_text.append(w[0])\n",
    "                stanford_tag.append(w[1])\n",
    "                audible_text.append(words[i].text)\n",
    "                audible_tag.append('O-')\n",
    "            \n",
    "    return(stanford_text, stanford_tag, audible_text, audible_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
